{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory\n",
    "\n",
    "In some applications like chatbots, it is important to remember previous interactions to keep the whole context of a conversation. Memory does provide you an easy way to handle this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hello my friend!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "history.add_ai_message(\"hello my friend!\")\n",
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_5932\\3648818006.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi!\\nAI: hello my friend!'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"hello my friend!\")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What is the capital of France?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the capital of France?',\n",
       " 'history': '',\n",
       " 'response': 'The capital of France is **Paris**! ðŸŒŸ\\n\\nParis has been the political and cultural heart of France for centuries. Itâ€™s home to iconic landmarks like the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum (where you can see the Mona Lisa). The city is also famous for its charming cafÃ©s, worldâ€‘class fashion boutiques, and vibrant art scene. Whether youâ€™re strolling along the Seine or exploring the historic Marais district, Paris offers a blend of history, romance, and modernity that makes it truly unique. If you ever plan to visit, donâ€™t miss the chance to try some authentic croissants and maybe catch a sunset from Montmartre!'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from pydantic import SecretStr\n",
    "\n",
    "class MyChatModel(ChatOpenAI):\n",
    "  def get_num_tokens_from_messages(self, messages):\n",
    "        # Simple fallback: approximate using string length / 4\n",
    "        text = \"\".join(m.content for m in messages)\n",
    "        return len(text.split())  # crude approximation\n",
    "\n",
    "llm = MyChatModel(\n",
    "    model=os.getenv(\"MODEL\", \"\"),\n",
    "    base_url=os.getenv(\"API_URL\", \"\"),\n",
    "    api_key=SecretStr(os.getenv(\"API_KEY\", \"\")),\n",
    "    temperature=0\n",
    ")\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=ConversationBufferMemory()\n",
    ")\n",
    "conversation.invoke(input={\"input\": \"What is the capital of France?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is the capital of France?\n",
      "AI: The capital of France is **Paris**.\n",
      "Human: Whats the best food there?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats the best food there?',\n",
       " 'history': 'Human: What is the capital of France?\\nAI: The capital of France is **Paris**.',\n",
       " 'response': \"Ah, youâ€™re in for a culinary adventure! France isnâ€™t just famous for its wine and cheeseâ€”though those are absolutely essentialâ€”but also for a wide array of dishes that showcase regional flavors, meticulous techniques, and centuriesâ€‘old traditions. Hereâ€™s a quick tour of some mustâ€‘try foods when youâ€™re strolling through Paris (and beyond):\\n\\n| Dish | What It Is | Why Itâ€™s Iconic | Where to Try |\\n|------|------------|-----------------|--------------|\\n| **Croissant** | Flaky, buttery laminated pastry | Symbol of French breakfast; perfected in Viennese bakeries that migrated to France. | *Le Pain Quotidien* or any local boulangerie on Rue Montorgueil. |\\n| **Baguette** | Long, crusty loaf with a crisp exterior and airy interior | The quintessential French bread; the baguette is protected by law (only certain bakers may produce it). | *PoilÃ¢ne* in Parisâ€‘7th or any street-side bakery. |\\n| **Escargot Ã  la Bourguignonne** | Snails cooked in garlic, parsley butter, and white wine | A classic from Burgundy; showcases the French love for â€œeating the whole animal.â€ | *Le Comptoir du Relais* (French cuisine with a twist). |\\n| **Coq au Vin** | Chicken braised in red wine, mushrooms, onions, and bacon | A rustic dish that turned into haute cuisine; demonstrates slowâ€‘cooking techniques. | *Lâ€™ArpÃ¨ge* or any traditional bistro in the Latin Quarter. |\\n| **Bouillabaisse** | ProvenÃ§al fish stew with saffron, fennel, and orange zest | Originated from Marseille fishermen; now a gourmet staple. | *Le Miramar* in Marseille or *La Table du MarchÃ©* in Paris. |\\n| **Quiche Lorraine** | Savory tart filled with eggs, cream, bacon, and cheese | A classic French pastry thatâ€™s both simple and elegant. | *CafÃ© de la Paix* near the Opera. |\\n| **CrÃªpes (sweet & savory)** | Thin pancakes; can be filled with Nutella, lemonâ€‘sugar, or ham & cheese | Versatile comfort food; sweet crÃªpes are a dessert staple, while galettes are savory buckwheat versions. | *CafÃ© des Deux Moulins* (famous from â€œAmÃ©lieâ€) for sweet; *Le Petit CafÃ©* in Montmartre for savory. |\\n| **Macarons** | Delicate almond meringue cookies with ganache filling | Known worldwide, theyâ€™re a testament to French patisserie precision. | *LadurÃ©e* on Rue de Rivoli or *Pierre HermÃ©* on Rue Bonaparte. |\\n| **Foie Gras** | Fatty duck or goose liver pÃ¢tÃ© | A luxury delicacy that sparked culinary debates; showcases French foieâ€‘gras tradition. | *Le Cinq* in the 8th arrondissement (for a highâ€‘end experience). |\\n| **Ratatouille** | Stewed vegetable medley of eggplant, zucchini, peppers, and tomatoes | ProvenÃ§al dish thatâ€™s both healthy and flavorful; often served as a side or main. | *Chez L'Ami Jean* in the 7th for a hearty version. |\\n| **CrÃ¨me BrÃ»lÃ©e** | Custard base topped with caramelized sugar | Classic French dessert; the contrast of textures is pure bliss. | *CafÃ© Marly* near the Louvre. |\\n\\n### Quick Tips for Food Lovers\\n\\n1. **Seasonal Markets:** Visit MarchÃ© dâ€™Aligre or MarchÃ© des Enfants Rouges to sample fresh produce, cheeses, and charcuterie.\\n2. **Cheese Tasting:** France has over 400 varietiesâ€”try a cheese board (plateau de fromages) featuring Brie, Camembert, Roquefort, and ComtÃ©.\\n3. **Wine Pairing:** Pair your meal with a local wine: Burgundy for coq au vin, Champagne for celebratory occasions, or a crisp Sauvignon Blanc from the Loire Valley.\\n4. **Street Food:** Grab a *falafel* in the Marais (Lâ€™As du Fallafel) or a *crÃªpe* from a street vendorâ€”both are iconic and budgetâ€‘friendly.\\n\\n### A Personal Recommendation\\n\\nIf youâ€™re looking for an unforgettable experience, head to **Le Cinq** at Four Seasons George V. The chef, Christian Le Squer, blends classic French techniques with modern flair. Try the foie gras terrine followed by a delicate soufflÃ©, all paired with a vintage Bordeaux. Itâ€™s pricey but worth it if you want to taste the pinnacle of French gastronomy.\\n\\nEnjoy your culinary journeyâ€”Bon appÃ©tit!\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input={\"input\": \"Whats the best food there?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationSummaryMemory\n",
    "\n",
    "When inputs get long, we might not want to send the whole conversation, but rather a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "review = \"I ordered Pizza Salami for 9.99$ and it was awesome! \\\n",
    "The pizza was delivered on time and was still hot when I received it. \\\n",
    "The crust was thin and crispy, and the toppings were fresh and flavorful. \\\n",
    "The Salami was well-cooked and complemented the cheese perfectly. \\\n",
    "The price was reasonable and I believe I got my money's worth. \\\n",
    "Overall, I am very satisfied with my order and I would recommend this pizza place to others.\"\n",
    "\n",
    "summary_memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100) # If Token is 1000, no summary will be created\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"Hello, how can I help you today?\"},\n",
    "    {\"output\": \"Could you analyze a review for me?\"},\n",
    ")\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"Sure, I'd be happy to. Could you provide the review?\"},\n",
    "    {\"output\": f\"{review}\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, how can I help you today?\n",
      "AI: Could you analyze a review for me?\n",
      "Human: Sure, I'd be happy to. Could you provide the review?\n",
      "AI: I ordered Pizza Salami for 9.99$ and it was awesome! The pizza was delivered on time and was still hot when I received it. The crust was thin and crispy, and the toppings were fresh and flavorful. The Salami was well-cooked and complemented the cheese perfectly. The price was reasonable and I believe I got my money's worth. Overall, I am very satisfied with my order and I would recommend this pizza place to others.\n",
      "Human: Thank you very much!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Thank you very much!',\n",
       " 'history': \"Human: Hello, how can I help you today?\\nAI: Could you analyze a review for me?\\nHuman: Sure, I'd be happy to. Could you provide the review?\\nAI: I ordered Pizza Salami for 9.99$ and it was awesome! The pizza was delivered on time and was still hot when I received it. The crust was thin and crispy, and the toppings were fresh and flavorful. The Salami was well-cooked and complemented the cheese perfectly. The price was reasonable and I believe I got my money's worth. Overall, I am very satisfied with my order and I would recommend this pizza place to others.\",\n",
       " 'response': 'Youâ€™re welcome! Iâ€™m glad you enjoyed the pizza. If thereâ€™s anything else youâ€™d like me to dig intoâ€”maybe a deeper sentiment breakdown, comparison with other reviews, or even some suggestions on how to improve your next orderâ€”just let me know. Iâ€™m here to help!'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=summary_memory\n",
    ")\n",
    "\n",
    "conversation.invoke(input=\"Thank you very much!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm=MyChatModel(client=<openai.resources.chat.completions.completions.Completions object at 0x000002134D020A50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002134D0211D0>, root_client=<openai.OpenAI object at 0x000002134D020CD0>, root_async_client=<openai.AsyncOpenAI object at 0x000002134D021450>, model_name='openai/gpt-oss-20b', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='http://127.0.0.1:1234/v1') chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Thank you very much!', additional_kwargs={}, response_metadata={}), AIMessage(content='Youâ€™re welcome! Iâ€™m glad you enjoyed the pizza. If thereâ€™s anything else youâ€™d like me to dig intoâ€”maybe a deeper sentiment breakdown, comparison with other reviews, or even some suggestions on how to improve your next orderâ€”just let me know. Iâ€™m here to help!', additional_kwargs={}, response_metadata={})]) max_token_limit=100 moving_summary_buffer='The human greets the AI and asks how it can help. The AI offers to analyze a review. The human agrees and requests the review text. The AI supplies a detailed positive review of a $9.99 Pizza Salami order, noting timely delivery, hot pizza, thin crispy crust, fresh toppings, wellâ€‘cooked salami, reasonable price, overall satisfaction, and recommendation.'\n"
     ]
    }
   ],
   "source": [
    "print(summary_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi!\\nAI: hello my friend!'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
