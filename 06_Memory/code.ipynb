{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory\n",
    "\n",
    "In some applications like chatbots, it is important to remember previous interactions to keep the whole context of a conversation. Memory does provide you an easy way to handle this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hello my friend!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "history.add_ai_message(\"hello my friend!\")\n",
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_5932\\3648818006.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi!\\nAI: hello my friend!'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"hello my friend!\")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What is the capital of France?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the capital of France?',\n",
       " 'history': '',\n",
       " 'response': 'The capital of France is **Paris**! 🌟\\n\\nParis has been the political and cultural heart of France for centuries. It’s home to iconic landmarks like the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum (where you can see the Mona Lisa). The city is also famous for its charming cafés, world‑class fashion boutiques, and vibrant art scene. Whether you’re strolling along the Seine or exploring the historic Marais district, Paris offers a blend of history, romance, and modernity that makes it truly unique. If you ever plan to visit, don’t miss the chance to try some authentic croissants and maybe catch a sunset from Montmartre!'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from pydantic import SecretStr\n",
    "\n",
    "class MyChatModel(ChatOpenAI):\n",
    "  def get_num_tokens_from_messages(self, messages):\n",
    "        # Simple fallback: approximate using string length / 4\n",
    "        text = \"\".join(m.content for m in messages)\n",
    "        return len(text.split())  # crude approximation\n",
    "\n",
    "llm = MyChatModel(\n",
    "    model=os.getenv(\"MODEL\", \"\"),\n",
    "    base_url=os.getenv(\"API_URL\", \"\"),\n",
    "    api_key=SecretStr(os.getenv(\"API_KEY\", \"\")),\n",
    "    temperature=0\n",
    ")\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=ConversationBufferMemory()\n",
    ")\n",
    "conversation.invoke(input={\"input\": \"What is the capital of France?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is the capital of France?\n",
      "AI: The capital of France is **Paris**.\n",
      "Human: Whats the best food there?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats the best food there?',\n",
       " 'history': 'Human: What is the capital of France?\\nAI: The capital of France is **Paris**.',\n",
       " 'response': \"Ah, you’re in for a culinary adventure! France isn’t just famous for its wine and cheese—though those are absolutely essential—but also for a wide array of dishes that showcase regional flavors, meticulous techniques, and centuries‑old traditions. Here’s a quick tour of some must‑try foods when you’re strolling through Paris (and beyond):\\n\\n| Dish | What It Is | Why It’s Iconic | Where to Try |\\n|------|------------|-----------------|--------------|\\n| **Croissant** | Flaky, buttery laminated pastry | Symbol of French breakfast; perfected in Viennese bakeries that migrated to France. | *Le Pain Quotidien* or any local boulangerie on Rue Montorgueil. |\\n| **Baguette** | Long, crusty loaf with a crisp exterior and airy interior | The quintessential French bread; the baguette is protected by law (only certain bakers may produce it). | *Poilâne* in Paris‑7th or any street-side bakery. |\\n| **Escargot à la Bourguignonne** | Snails cooked in garlic, parsley butter, and white wine | A classic from Burgundy; showcases the French love for “eating the whole animal.” | *Le Comptoir du Relais* (French cuisine with a twist). |\\n| **Coq au Vin** | Chicken braised in red wine, mushrooms, onions, and bacon | A rustic dish that turned into haute cuisine; demonstrates slow‑cooking techniques. | *L’Arpège* or any traditional bistro in the Latin Quarter. |\\n| **Bouillabaisse** | Provençal fish stew with saffron, fennel, and orange zest | Originated from Marseille fishermen; now a gourmet staple. | *Le Miramar* in Marseille or *La Table du Marché* in Paris. |\\n| **Quiche Lorraine** | Savory tart filled with eggs, cream, bacon, and cheese | A classic French pastry that’s both simple and elegant. | *Café de la Paix* near the Opera. |\\n| **Crêpes (sweet & savory)** | Thin pancakes; can be filled with Nutella, lemon‑sugar, or ham & cheese | Versatile comfort food; sweet crêpes are a dessert staple, while galettes are savory buckwheat versions. | *Café des Deux Moulins* (famous from “Amélie”) for sweet; *Le Petit Café* in Montmartre for savory. |\\n| **Macarons** | Delicate almond meringue cookies with ganache filling | Known worldwide, they’re a testament to French patisserie precision. | *Ladurée* on Rue de Rivoli or *Pierre Hermé* on Rue Bonaparte. |\\n| **Foie Gras** | Fatty duck or goose liver pâté | A luxury delicacy that sparked culinary debates; showcases French foie‑gras tradition. | *Le Cinq* in the 8th arrondissement (for a high‑end experience). |\\n| **Ratatouille** | Stewed vegetable medley of eggplant, zucchini, peppers, and tomatoes | Provençal dish that’s both healthy and flavorful; often served as a side or main. | *Chez L'Ami Jean* in the 7th for a hearty version. |\\n| **Crème Brûlée** | Custard base topped with caramelized sugar | Classic French dessert; the contrast of textures is pure bliss. | *Café Marly* near the Louvre. |\\n\\n### Quick Tips for Food Lovers\\n\\n1. **Seasonal Markets:** Visit Marché d’Aligre or Marché des Enfants Rouges to sample fresh produce, cheeses, and charcuterie.\\n2. **Cheese Tasting:** France has over 400 varieties—try a cheese board (plateau de fromages) featuring Brie, Camembert, Roquefort, and Comté.\\n3. **Wine Pairing:** Pair your meal with a local wine: Burgundy for coq au vin, Champagne for celebratory occasions, or a crisp Sauvignon Blanc from the Loire Valley.\\n4. **Street Food:** Grab a *falafel* in the Marais (L’As du Fallafel) or a *crêpe* from a street vendor—both are iconic and budget‑friendly.\\n\\n### A Personal Recommendation\\n\\nIf you’re looking for an unforgettable experience, head to **Le Cinq** at Four Seasons George V. The chef, Christian Le Squer, blends classic French techniques with modern flair. Try the foie gras terrine followed by a delicate soufflé, all paired with a vintage Bordeaux. It’s pricey but worth it if you want to taste the pinnacle of French gastronomy.\\n\\nEnjoy your culinary journey—Bon appétit!\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input={\"input\": \"Whats the best food there?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationSummaryMemory\n",
    "\n",
    "When inputs get long, we might not want to send the whole conversation, but rather a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "review = \"I ordered Pizza Salami for 9.99$ and it was awesome! \\\n",
    "The pizza was delivered on time and was still hot when I received it. \\\n",
    "The crust was thin and crispy, and the toppings were fresh and flavorful. \\\n",
    "The Salami was well-cooked and complemented the cheese perfectly. \\\n",
    "The price was reasonable and I believe I got my money's worth. \\\n",
    "Overall, I am very satisfied with my order and I would recommend this pizza place to others.\"\n",
    "\n",
    "summary_memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100) # If Token is 1000, no summary will be created\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"Hello, how can I help you today?\"},\n",
    "    {\"output\": \"Could you analyze a review for me?\"},\n",
    ")\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"Sure, I'd be happy to. Could you provide the review?\"},\n",
    "    {\"output\": f\"{review}\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, how can I help you today?\n",
      "AI: Could you analyze a review for me?\n",
      "Human: Sure, I'd be happy to. Could you provide the review?\n",
      "AI: I ordered Pizza Salami for 9.99$ and it was awesome! The pizza was delivered on time and was still hot when I received it. The crust was thin and crispy, and the toppings were fresh and flavorful. The Salami was well-cooked and complemented the cheese perfectly. The price was reasonable and I believe I got my money's worth. Overall, I am very satisfied with my order and I would recommend this pizza place to others.\n",
      "Human: Thank you very much!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Thank you very much!',\n",
       " 'history': \"Human: Hello, how can I help you today?\\nAI: Could you analyze a review for me?\\nHuman: Sure, I'd be happy to. Could you provide the review?\\nAI: I ordered Pizza Salami for 9.99$ and it was awesome! The pizza was delivered on time and was still hot when I received it. The crust was thin and crispy, and the toppings were fresh and flavorful. The Salami was well-cooked and complemented the cheese perfectly. The price was reasonable and I believe I got my money's worth. Overall, I am very satisfied with my order and I would recommend this pizza place to others.\",\n",
       " 'response': 'You’re welcome! I’m glad you enjoyed the pizza. If there’s anything else you’d like me to dig into—maybe a deeper sentiment breakdown, comparison with other reviews, or even some suggestions on how to improve your next order—just let me know. I’m here to help!'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=summary_memory\n",
    ")\n",
    "\n",
    "conversation.invoke(input=\"Thank you very much!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm=MyChatModel(client=<openai.resources.chat.completions.completions.Completions object at 0x000002134D020A50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002134D0211D0>, root_client=<openai.OpenAI object at 0x000002134D020CD0>, root_async_client=<openai.AsyncOpenAI object at 0x000002134D021450>, model_name='openai/gpt-oss-20b', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='http://127.0.0.1:1234/v1') chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Thank you very much!', additional_kwargs={}, response_metadata={}), AIMessage(content='You’re welcome! I’m glad you enjoyed the pizza. If there’s anything else you’d like me to dig into—maybe a deeper sentiment breakdown, comparison with other reviews, or even some suggestions on how to improve your next order—just let me know. I’m here to help!', additional_kwargs={}, response_metadata={})]) max_token_limit=100 moving_summary_buffer='The human greets the AI and asks how it can help. The AI offers to analyze a review. The human agrees and requests the review text. The AI supplies a detailed positive review of a $9.99 Pizza Salami order, noting timely delivery, hot pizza, thin crispy crust, fresh toppings, well‑cooked salami, reasonable price, overall satisfaction, and recommendation.'\n"
     ]
    }
   ],
   "source": [
    "print(summary_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi!\\nAI: hello my friend!'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
